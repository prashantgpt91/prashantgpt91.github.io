---
id: 1
title: "Attention Is All You Need"
authors: "Vaswani et al."
description: "Revolutionary paper that introduced the Transformer architecture, fundamentally changing how we approach sequence modeling in NLP."
year: "2017"
venue: "NIPS"
category: "nlp"
tags: ["NLP", "Deep Learning", "Transformers"]
url: "#"
---
